{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sentiment Analysis of Amazon Product Reviews\n",
        "\n",
        "This notebook performs sentiment analysis on Amazon product reviews using\n",
        "Natural Language Processing (NLP) techniques.\n",
        "\n",
        "The analysis uses:\n",
        "- **spaCy** for text processing\n",
        "- **SpacyTextBlob** for sentiment polarity analysis\n",
        "- **Pandas** for data handling\n",
        "\n",
        "The goal is to classify product reviews as **positive**, **negative**, or\n",
        "**neutral**, and to explore similarity between reviews.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Imports and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "import spacytextblob.spacytextblob as spacytextblob_component\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2:  Load spaCy model and add SpacyTextBlob to the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the spaCy English medium model\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "# Add SpacyTextBlob to the spaCy pipeline\n",
        "nlp.add_pipe(\"spacytextblob\")\n",
        "nlp.meta[\"spacytextblob_component\"] = (\n",
        "    spacytextblob_component.SpacyTextBlob.__name__\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the Amazon product reviews dataset\n",
        "file_path = \"Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv\"\n",
        "\n",
        "try:\n",
        "    dataframe = pd.read_csv(file_path)\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Dataset file not found.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Select and Clean Review Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of reviews after cleaning: 28332\n"
          ]
        }
      ],
      "source": [
        "# Remove missing values from the reviews column\n",
        "clean_data = dataframe.dropna(subset=[\"reviews.text\"])\n",
        "\n",
        "# Select the reviews.text column\n",
        "reviews_data = clean_data[\"reviews.text\"]\n",
        "\n",
        "print(f\"Total number of reviews after cleaning: {len(reviews_data)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5: Text Preprocessing Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Cleans review text by removing stop words, punctuation,\n",
        "    lemmatizing words, and converting text to lowercase.\n",
        "    \"\"\"\n",
        "    doc = nlp(text)\n",
        "\n",
        "    clean_tokens = [\n",
        "        token.lemma_.lower().strip()\n",
        "        for token in doc\n",
        "        if not token.is_stop and not token.is_punct and token.text.strip()\n",
        "    ]\n",
        "\n",
        "    return \" \".join(clean_tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 6: Sentiment Analysis Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_sentiment(review_text):\n",
        "    \"\"\"\n",
        "    Analyzes sentiment using SpacyTextBlob.\n",
        "\n",
        "    Returns:\n",
        "        polarity (float): Sentiment strength (-1 to 1)\n",
        "        sentiment (str): Positive, Negative, or Neutral\n",
        "    \"\"\"\n",
        "    doc = nlp(review_text)\n",
        "    polarity = doc._.blob.polarity\n",
        "\n",
        "    if polarity > 0.1:\n",
        "        sentiment = \"Positive\"\n",
        "    elif polarity < -0.1:\n",
        "        sentiment = \"Negative\"\n",
        "    else:\n",
        "        sentiment = \"Neutral\"\n",
        "\n",
        "    return polarity, sentiment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 7: Test Sentiment on Sample Reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========== SENTIMENT ANALYSIS SAMPLES ==========\n",
            "\n",
            "Review Index: 0\n",
            "Original Review: I order 3 of them and one of the item is bad quality. Is missing backup spring so I have to put a pcs of aluminum to mak...\n",
            "Sentiment: Negative\n",
            "Polarity Score: -0.70\n",
            "\n",
            "Review Index: 50\n",
            "Original Review: I definitely love the price and quantity.. My kids go tthrough them to fast. At least these will last a while.....\n",
            "Sentiment: Positive\n",
            "Polarity Score: 0.35\n",
            "\n",
            "Review Index: 100\n",
            "Original Review: As a teacher, I need tons of batteries, but I refused to spend excessive amounts on them, so I figured this was the best...\n",
            "Sentiment: Positive\n",
            "Polarity Score: 0.27\n"
          ]
        }
      ],
      "source": [
        "print(\"========== SENTIMENT ANALYSIS SAMPLES ==========\")\n",
        "\n",
        "sample_indices = [0, 50, 100]\n",
        "\n",
        "for idx in sample_indices:\n",
        "    if idx >= len(reviews_data):\n",
        "        continue\n",
        "\n",
        "    original_review = reviews_data.iloc[idx]\n",
        "    processed_review = preprocess_text(original_review)\n",
        "\n",
        "    polarity, sentiment = analyze_sentiment(processed_review)\n",
        "\n",
        "    print(f\"\\nReview Index: {idx}\")\n",
        "    print(f\"Original Review: {original_review[:120]}...\")\n",
        "    print(f\"Sentiment: {sentiment}\")\n",
        "    print(f\"Polarity Score: {polarity:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 8: Review Similarity Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "========== REVIEW SIMILARITY ==========\n",
            "Similarity score between Review 0 and Review 1: 0.75\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n========== REVIEW SIMILARITY ==========\")\n",
        "\n",
        "if len(reviews_data) >= 2:\n",
        "    review_a = nlp(preprocess_text(reviews_data.iloc[0]))\n",
        "    review_b = nlp(preprocess_text(reviews_data.iloc[1]))\n",
        "\n",
        "    similarity_score = review_a.similarity(review_b)\n",
        "\n",
        "    print(\n",
        "        \"Similarity score between Review 0 and Review 1: \"\n",
        "        f\"{similarity_score:.2f}\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 9: Improvements and Next Steps\n",
        "\n",
        "To improve the separation between neutral and polarized reviews, refine the polarity threshold by narrowing the neutral band around zero (for example, **-0.05 to 0.05**) and validating the choice against labeled samples. Because this approach is rule-based, it may miss sarcasm and domain-specific nuance. A strong next step is to evaluate transformer-based models (e.g., BERT). Hugging Face provides pretrained models that can be fine-tuned with a classification layer on labeled data to predict sentiment or emotions. See: https://huggingface.co/blog/bert-101"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
