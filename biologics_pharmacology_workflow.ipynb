{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Biologics Pharmacology AI/ML Workflow Notebook\n",
        "\n",
        "This notebook provides an interactive, end-to-end walkthrough for building and validating data-driven models to support early decisions in biologics drug development."
      ],
      "id": "272d0afd"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notebook flow (separated stages)\n",
        "\n",
        "1. **Imports**\n",
        "2. **Preprocessing**\n",
        "3. **Cleaning of data**\n",
        "4. **Introducing a model**\n",
        "5. **Training**\n",
        "6. **Testing**\n",
        "7. **Giving predictions**\n",
        "\n",
        "This structure is intentionally separated so each step is easy to follow in Jupyter."
      ],
      "id": "f03b142e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 1) Imports\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from IPython.display import display\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "PROJECT_ROOT = Path.cwd()\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "from biologics_pharmacology.decision_support import rank_candidates\n",
        "from biologics_pharmacology.modeling import (\n",
        "    BiologicsModelArtifacts,\n",
        "    build_pipeline,\n",
        "    run_grouped_cross_validation,\n",
        ")\n",
        "from biologics_pharmacology.schema import (\n",
        "    CATEGORICAL_FEATURES,\n",
        "    GROUP_COLUMN,\n",
        "    ID_COLUMN,\n",
        "    NUMERIC_FEATURES,\n",
        "    TARGET_COLUMNS,\n",
        "    feature_columns,\n",
        "    required_columns,\n",
        "    validate_dataset_schema,\n",
        ")\n",
        "from scripts.generate_synthetic_biologics_data import generate_dataset\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\", context=\"notebook\")\n",
        "pd.set_option(\"display.max_columns\", 120)\n",
        "pd.set_option(\"display.width\", 140)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "181af518"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Raw data ingestion\n",
        "\n",
        "Load existing integrated biologics data if present, otherwise generate synthetic data for demonstration."
      ],
      "id": "6c86c4f5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_path = Path(\"data/synthetic_biologics.csv\")\n",
        "data_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "if data_path.exists():\n",
        "    raw_df = pd.read_csv(data_path)\n",
        "    source = \"loaded from existing CSV\"\n",
        "else:\n",
        "    raw_df = generate_dataset(n_samples=500, seed=42)\n",
        "    raw_df.to_csv(data_path, index=False)\n",
        "    source = \"generated and saved\"\n",
        "\n",
        "print(f\"Dataset source: {source}\")\n",
        "print(f\"Raw shape: {raw_df.shape}\")\n",
        "print(f\"Unique molecule families: {raw_df[GROUP_COLUMN].nunique()}\")\n",
        "\n",
        "display(raw_df.head())"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "e77b5b51"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Preprocessing\n",
        "\n",
        "In this step we standardize categorical text and coerce numeric columns to numeric dtype."
      ],
      "id": "13dc393b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "preprocessed_df = raw_df.copy()\n",
        "\n",
        "for col in CATEGORICAL_FEATURES + [GROUP_COLUMN]:\n",
        "    preprocessed_df[col] = (\n",
        "        preprocessed_df[col]\n",
        "        .astype(str)\n",
        "        .str.strip()\n",
        "        .str.lower()\n",
        "    )\n",
        "\n",
        "for col in NUMERIC_FEATURES + TARGET_COLUMNS:\n",
        "    preprocessed_df[col] = pd.to_numeric(preprocessed_df[col], errors=\"coerce\")\n",
        "\n",
        "print(\"Missing values after type coercion (top 10):\")\n",
        "display(\n",
        "    preprocessed_df[required_columns()]\n",
        "    .isna()\n",
        "    .sum()\n",
        "    .sort_values(ascending=False)\n",
        "    .head(10)\n",
        "    .to_frame(\"missing_count\")\n",
        ")\n",
        "\n",
        "display(preprocessed_df.head())"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "e63e7fcc"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Cleaning of data\n",
        "\n",
        "This step removes duplicate IDs, fills missing values, and applies basic range guards for percentage fields."
      ],
      "id": "3b76e46f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "clean_df = preprocessed_df.copy()\n",
        "\n",
        "rows_before = len(clean_df)\n",
        "clean_df = clean_df.drop_duplicates(subset=[ID_COLUMN]).reset_index(drop=True)\n",
        "rows_after = len(clean_df)\n",
        "\n",
        "for col in NUMERIC_FEATURES + TARGET_COLUMNS:\n",
        "    clean_df[col] = clean_df[col].fillna(clean_df[col].median())\n",
        "\n",
        "for col in CATEGORICAL_FEATURES + [GROUP_COLUMN]:\n",
        "    clean_df[col] = clean_df[col].fillna(\"unknown\")\n",
        "\n",
        "pct_cols = [col for col in clean_df.columns if col.endswith(\"_pct\")]\n",
        "clean_df[pct_cols] = clean_df[pct_cols].clip(lower=0, upper=100)\n",
        "\n",
        "validate_dataset_schema(clean_df)\n",
        "\n",
        "print(f\"Rows before cleaning: {rows_before}\")\n",
        "print(f\"Rows after cleaning:  {rows_after}\")\n",
        "print(\"Any missing values left in required columns:\", clean_df[required_columns()].isna().sum().sum())\n",
        "\n",
        "display(clean_df[required_columns()].describe(include=\"all\").transpose().head(12))"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "3052014b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Introducing a model\n",
        "\n",
        "We use a multi-output pipeline:\n",
        "\n",
        "- Imputation + one-hot encoding\n",
        "- Random forest regressor wrapped for multi-target prediction\n",
        "- Targets: PK half-life, PD response, and severe AE rate"
      ],
      "id": "92d04aa6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = build_pipeline()\n",
        "\n",
        "print(\"Model pipeline object:\")\n",
        "display(model)\n",
        "\n",
        "print(\"\\nFeature summary\")\n",
        "print(f\"- Numeric features: {len(NUMERIC_FEATURES)}\")\n",
        "print(f\"- Categorical features: {len(CATEGORICAL_FEATURES)}\")\n",
        "print(f\"- Total model features: {len(feature_columns())}\")\n",
        "print(f\"- Targets: {TARGET_COLUMNS}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "f2258bff"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Training\n",
        "\n",
        "We split by molecule family using `GroupShuffleSplit` to avoid leakage across related molecules."
      ],
      "id": "2491b969"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X = clean_df[feature_columns()].copy()\n",
        "y = clean_df[TARGET_COLUMNS].copy()\n",
        "groups = clean_df[GROUP_COLUMN]\n",
        "\n",
        "splitter = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "train_idx, test_idx = next(splitter.split(X, y, groups=groups))\n",
        "\n",
        "train_df = clean_df.iloc[train_idx].reset_index(drop=True)\n",
        "test_df = clean_df.iloc[test_idx].reset_index(drop=True)\n",
        "\n",
        "model.fit(train_df[feature_columns()], train_df[TARGET_COLUMNS])\n",
        "\n",
        "artifacts = BiologicsModelArtifacts(\n",
        "    pipeline=model,\n",
        "    feature_columns=feature_columns(),\n",
        "    target_columns=TARGET_COLUMNS,\n",
        "    group_column=GROUP_COLUMN,\n",
        ")\n",
        "\n",
        "model_path = Path(\"models/biologics_multitask_model.joblib\")\n",
        "model_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "joblib.dump(artifacts, model_path)\n",
        "\n",
        "print(f\"Training rows: {len(train_df)}\")\n",
        "print(f\"Testing rows:  {len(test_df)}\")\n",
        "print(f\"Saved trained artifact to: {model_path}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "4b8ff126"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Testing\n",
        "\n",
        "We evaluate on a held-out test set and also report grouped cross-validation metrics."
      ],
      "id": "139d2a63"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "test_predictions = pd.DataFrame(\n",
        "    model.predict(test_df[feature_columns()]),\n",
        "    columns=TARGET_COLUMNS,\n",
        "    index=test_df.index,\n",
        ")\n",
        "\n",
        "holdout_metrics = []\n",
        "for target in TARGET_COLUMNS:\n",
        "    holdout_metrics.append(\n",
        "        {\n",
        "            \"target\": target,\n",
        "            \"holdout_mae\": mean_absolute_error(test_df[target], test_predictions[target]),\n",
        "            \"holdout_r2\": r2_score(test_df[target], test_predictions[target]),\n",
        "        }\n",
        "    )\n",
        "\n",
        "holdout_metrics_df = pd.DataFrame(holdout_metrics).round(3)\n",
        "print(\"Holdout test metrics:\")\n",
        "display(holdout_metrics_df)\n",
        "\n",
        "cv_metrics = run_grouped_cross_validation(clean_df, n_splits=5)\n",
        "cv_summary = cv_metrics.groupby(\"target\")[[\"mae\", \"r2\"]].agg([\"mean\", \"std\"]).round(3)\n",
        "print(\"\\nGrouped CV summary:\")\n",
        "display(cv_summary)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "09eb86af"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Giving predictions\n",
        "\n",
        "Below we generate record-level predictions and a ranked candidate list for decision support."
      ],
      "id": "29094f29"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "test_results = test_df[[ID_COLUMN, GROUP_COLUMN] + TARGET_COLUMNS].copy()\n",
        "for target in TARGET_COLUMNS:\n",
        "    test_results[f\"pred_{target}\"] = test_predictions[target]\n",
        "\n",
        "print(\"Sample predictions on held-out test set:\")\n",
        "display(\n",
        "    test_results[\n",
        "        [\n",
        "            ID_COLUMN,\n",
        "            \"clinical_pk_half_life_day\",\n",
        "            \"pred_clinical_pk_half_life_day\",\n",
        "            \"clinical_pd_response_pct\",\n",
        "            \"pred_clinical_pd_response_pct\",\n",
        "            \"severe_ae_rate_pct\",\n",
        "            \"pred_severe_ae_rate_pct\",\n",
        "        ]\n",
        "    ].head(12).round(3)\n",
        ")\n",
        "\n",
        "candidate_table = clean_df[[ID_COLUMN] + feature_columns()].copy()\n",
        "ranked_candidates = rank_candidates(\n",
        "    artifacts=artifacts,\n",
        "    candidates=candidate_table,\n",
        "    top_k=15,\n",
        ")\n",
        "\n",
        "print(\"Top ranked candidates for early development decisions:\")\n",
        "display(\n",
        "    ranked_candidates[\n",
        "        [\n",
        "            ID_COLUMN,\n",
        "            \"pred_clinical_pk_half_life_day\",\n",
        "            \"pred_clinical_pd_response_pct\",\n",
        "            \"pred_severe_ae_rate_pct\",\n",
        "            \"decision_score\",\n",
        "        ]\n",
        "    ].round(3)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "7f79c104"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optional visualization: feature importance by target\n",
        "\n",
        "Because the model is multi-output, we inspect importances separately for PK, PD, and safety."
      ],
      "id": "76100f9a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "preprocessor = artifacts.pipeline.named_steps[\"preprocess\"]\n",
        "regressor = artifacts.pipeline.named_steps[\"regressor\"]\n",
        "\n",
        "feature_names = preprocessor.get_feature_names_out()\n",
        "\n",
        "target_importance_tables = {}\n",
        "fig, axes = plt.subplots(1, len(artifacts.target_columns), figsize=(20, 5))\n",
        "\n",
        "for idx, (target, estimator) in enumerate(zip(artifacts.target_columns, regressor.estimators_)):\n",
        "    importance_df = pd.DataFrame(\n",
        "        {\n",
        "            \"feature\": feature_names,\n",
        "            \"importance\": estimator.feature_importances_,\n",
        "        }\n",
        "    ).sort_values(\"importance\", ascending=False)\n",
        "\n",
        "    target_importance_tables[target] = importance_df\n",
        "\n",
        "    top_importance = importance_df.head(15).iloc[::-1]\n",
        "    axes[idx].barh(top_importance[\"feature\"], top_importance[\"importance\"], color=\"#4C78A8\")\n",
        "    axes[idx].set_title(f\"Top features: {target}\")\n",
        "    axes[idx].set_xlabel(\"Importance\")\n",
        "    axes[idx].tick_params(axis=\"y\", labelsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "for target in artifacts.target_columns:\n",
        "    print(f\"Top 10 features for {target}:\")\n",
        "    display(target_importance_tables[target].head(10).reset_index(drop=True))"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "75ccc0e6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Decision landscape view\n",
        "\n",
        "This plot shows how candidates balance efficacy, safety, and PK durability."
      ],
      "id": "3454ea6d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "scored_all = rank_candidates(\n",
        "    artifacts=artifacts,\n",
        "    candidates=candidate_table,\n",
        "    top_k=len(candidate_table),\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "scatter = sns.scatterplot(\n",
        "    data=scored_all,\n",
        "    x=\"pred_clinical_pd_response_pct\",\n",
        "    y=\"pred_severe_ae_rate_pct\",\n",
        "    size=\"pred_clinical_pk_half_life_day\",\n",
        "    hue=\"decision_score\",\n",
        "    palette=\"viridis\",\n",
        "    sizes=(20, 220),\n",
        "    alpha=0.75,\n",
        ")\n",
        "scatter.set_title(\"Candidate decision landscape\")\n",
        "scatter.set_xlabel(\"Predicted clinical PD response (%)\")\n",
        "scatter.set_ylabel(\"Predicted severe AE rate (%)\")\n",
        "\n",
        "for _, row in scored_all.head(5).iterrows():\n",
        "    plt.annotate(\n",
        "        row[\"molecule_id\"],\n",
        "        (row[\"pred_clinical_pd_response_pct\"], row[\"pred_severe_ae_rate_pct\"]),\n",
        "        xytext=(5, 5),\n",
        "        textcoords=\"offset points\",\n",
        "        fontsize=9,\n",
        "    )\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "scored_all[\n",
        "    [\n",
        "        \"molecule_id\",\n",
        "        \"decision_score\",\n",
        "        \"pred_clinical_pd_response_pct\",\n",
        "        \"pred_clinical_pk_half_life_day\",\n",
        "        \"pred_severe_ae_rate_pct\",\n",
        "    ]\n",
        "].head(10).round(3)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "a6de6d35"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Adapting this notebook to real R&D data\n",
        "\n",
        "To move from synthetic to real biologics programs:\n",
        "\n",
        "1. Replace `raw_df` with your governed integrated dataset.\n",
        "2. Keep required schema columns from `biologics_pharmacology/schema.py`.\n",
        "3. Preserve grouped validation by molecule family (or program-level grouping).\n",
        "4. Tune model settings and decision-score weights with QP and clinical stakeholders.\n",
        "5. Add uncertainty estimates before deployment into portfolio decisions."
      ],
      "id": "186a8129"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}